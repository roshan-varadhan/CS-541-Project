{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ed37e23",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e216d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13e78210",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load sample dataset (Boston housing dataset)\n",
    "url = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/housing.csv'\n",
    "columns = ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', \n",
    "           'RM', 'AGE', 'DIS', 'RAD', 'TAX', \n",
    "           'PTRATIO', 'B', 'LSTAT', 'MEDV']\n",
    "\n",
    "df = pd.read_csv(url, header=None, names=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd94784e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
      "0  0.00632  18.0   2.31     0  0.538    NaN  65.2  4.0900    1  296.0   \n",
      "1  0.02731   0.0   7.07     0  0.469  6.421  78.9  4.9671    2  242.0   \n",
      "2  0.02729   0.0   7.07     0  0.469  7.185  61.1  4.9671    2  242.0   \n",
      "3  0.03237   0.0   2.18     0  0.458  6.998  45.8  6.0622    3  222.0   \n",
      "4  0.06905   0.0   2.18     0  0.458  7.147  54.2  6.0622    3  222.0   \n",
      "\n",
      "   PTRATIO       B  LSTAT  MEDV  \n",
      "0     15.3  396.90   4.98  24.0  \n",
      "1     17.8  396.90   9.14  21.6  \n",
      "2     17.8  392.83   4.03  34.7  \n",
      "3     18.7  394.63   2.94  33.4  \n",
      "4     18.7  396.90   5.33  36.2  \n"
     ]
    }
   ],
   "source": [
    "# Add artificial missing value (for testing purposes)\n",
    "df.loc[0, 'RM'] = None\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f5db29e",
   "metadata": {},
   "source": [
    "Loading API Key from ENV File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013868f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "token = os.getenv(\"HF_TOKEN\")\n",
    "\n",
    "API_URL = \"https://api-inference.huggingface.co/models/HuggingFaceH4/zephyr-7b-beta\"\n",
    "headers = {\"Authorization\": f\"Bearer {token}\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf9a5dae",
   "metadata": {},
   "source": [
    "Function for prompt to send to LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a7698132",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_prompt(row):\n",
    "    prompt = f\"\"\"\n",
    "    Analyze the following data row and identify any data quality issues, such as missing or inconsistent values. \n",
    "    Clearly state each issue and its location.\n",
    "\n",
    "    Data row:\n",
    "    {row.to_dict()}\n",
    "\n",
    "    Issues:\n",
    "    \"\"\"\n",
    "    return prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a0ead1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_hf(payload):\n",
    "    response = requests.post(API_URL, headers=headers, json=payload)\n",
    "    return response.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59cafe98",
   "metadata": {},
   "source": [
    "Receive the errors from LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6cee8b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_quality(row):\n",
    "    prompt = create_prompt(row)\n",
    "    output = query_hf({\n",
    "        \"inputs\": prompt,\n",
    "        \"parameters\": {\"max_new_tokens\": 100, \"temperature\": 0.2}\n",
    "    })\n",
    "\n",
    "    generated_text = output[0]['generated_text']\n",
    "    issues = generated_text.split('Issues:')[-1].strip()\n",
    "    return issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "51df2688",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected issues: 1. Missing value in 'RM' column. Location: 'RM' column.\n",
      "    2. 'RM' column is not present in the header row, which could indicate a potential naming error or missing column.\n",
      "    3. 'MEDV' value is rounded to two decimal places, which could indicate potential data rounding errors or inconsistencies.\n",
      "    4. 'MEDV' value is an outlier, as it is significantly lower than the other values in\n"
     ]
    }
   ],
   "source": [
    "# Test with first row\n",
    "row = df.iloc[0]\n",
    "issues = check_quality(row)\n",
    "print(\"Detected issues:\", issues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "72a4d2bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 0:\n",
      "1. Missing value in 'RM' column. Location: 'RM' column.\n",
      "    2. 'RM' column is not present in the header row, which could indicate a potential naming error or missing column.\n",
      "    3. 'MEDV' value is rounded to two decimal places, which could indicate potential data rounding errors or inconsistencies.\n",
      "    4. 'MEDV' value is an outlier, as it is significantly lower than the other values in\n",
      "----------------------------------------\n",
      "Row 1:\n",
      "1. Missing value: 'ZN' is missing a value. This is located at the second key-value pair in the dictionary.\n",
      "    2. Inconsistent value: 'NOX' has a value of 0.469, which is not a valid numerical value for NOX levels. This is located at the sixth key-value pair in the dictionary.\n",
      "    3. Inconsistent value: 'LSTAT' has a value of 9.1\n",
      "----------------------------------------\n",
      "Row 2:\n",
      "1. Missing value: 'ZN' is missing a value. Its location is in the dictionary key 'ZN'.\n",
      "    2. Inconsistent value: 'CHAS' should be either 0 or 1, but it is 0.0. Its location is in the dictionary key 'CHAS'.\n",
      "    3. Inconsistent value: 'NOX' should be a numerical value, but it is 0.469. Its location is in\n",
      "----------------------------------------\n",
      "Row 3:\n",
      "1. Missing value: 'ZN' is missing a value. This is located at the second index of the dictionary.\n",
      "    2. Inconsistent value: 'B' has an inconsistent value. While the other numerical features are decimal numbers, 'B' is an integer. This is located at the eleventh index of the dictionary.\n",
      "    3. Inconsistent value: 'LSTAT' has an inconsistent value. While the other numerical features are decimal numbers\n",
      "----------------------------------------\n",
      "Row 4:\n",
      "1. Missing value: 'ZN' is missing a value. This is located in the second column of the dictionary.\n",
      "    2. Inconsistent value: 'CHAS' should be either 0 or 1, but it is currently 0.0. This is located in the third column of the dictionary.\n",
      "    3. Inconsistent value: 'NOX' should be a numerical value, but it is currently a decimal value (0.458\n",
      "----------------------------------------\n",
      "Row 5:\n",
      "1. Missing value: 'ZN' is missing a value. This is located at the second key-value pair in the dictionary.\n",
      "    2. Inconsistent value: 'CHAS' has a value of 0.0, but this variable is a binary feature that should only take values of 0 or 1. This is located at the fourth key-value pair in the dictionary.\n",
      "    3. Inconsistent value: 'NOX' has a value\n",
      "----------------------------------------\n",
      "Row 6:\n",
      "1. Missing value: 'CHAS' should be either 0 or 1, but it is 0.0. This could be a data entry error or a missing value that needs to be imputed.\n",
      "    2. Inconsistent value: 'RM' is an integer, but it is being represented as a decimal value (6.012). This could be a formatting error or a data entry error.\n",
      "    3. Inconsistent value:\n",
      "----------------------------------------\n",
      "Row 7:\n",
      "1. Missing value: 'CHAS' should be either 0 or 1, but in this row it is 0.0, which is not a valid value. Location: 'CHAS' column.\n",
      "    2. Inconsistent value: 'B' should be a numerical value, but in this row it is '396.9', which is a string. Location: 'B' column.\n",
      "    3. Inconsistent value: 'MEDV\n",
      "----------------------------------------\n",
      "Row 8:\n",
      "1. Missing value: 'CHAS' should be a binary variable (0 or 1) indicating whether a particular property is located in a region with a river nearby. However, this row has a value of 0.0, which is not a valid binary value. This could be due to a data entry error or a missing value.\n",
      "    2. Inconsistent value: 'AGE' should represent the median value of houses built in the area. However, this row has\n",
      "----------------------------------------\n",
      "Row 9:\n",
      "1. Missing value: 'CHAS' should be a binary value (0 or 1) indicating whether a particular property is located in a high-crime area. However, the value in this row is 0.0, which is not a valid binary value. This issue is located in the 'CHAS' key-value pair.\n",
      "    2. Inconsistent value: The 'MEDV' value is 18.9, which is outside the expected range\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "for idx, row in df.head(10).iterrows():\n",
    "    print(f\"Row {idx}:\")\n",
    "    print(check_quality(row))\n",
    "    print('-' * 40)\n",
    "    time.sleep(1)  # to avoid rate limits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fcd70d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "for idx, row in df.head(10).iterrows():\n",
    "    issues = check_quality(row)\n",
    "    results.append({'index': idx, 'issues': issues})\n",
    "    time.sleep(1)\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_csv(\"llm_data_quality_results.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c20c0c58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
      "0    0.00632  18.0   2.31     0  0.538    NaN  65.2  4.0900    1  296.0   \n",
      "1    0.02731   0.0   7.07     0  0.469  6.421  78.9  4.9671    2  242.0   \n",
      "2    0.02729   0.0   7.07     0  0.469  7.185  61.1  4.9671    2  242.0   \n",
      "3    0.03237   0.0   2.18     0  0.458  6.998  45.8  6.0622    3  222.0   \n",
      "4    0.06905   0.0   2.18     0  0.458  7.147  54.2  6.0622    3  222.0   \n",
      "..       ...   ...    ...   ...    ...    ...   ...     ...  ...    ...   \n",
      "501  0.06263   0.0  11.93     0  0.573  6.593  69.1  2.4786    1  273.0   \n",
      "502  0.04527   0.0  11.93     0  0.573  6.120  76.7  2.2875    1  273.0   \n",
      "503  0.06076   0.0  11.93     0  0.573  6.976  91.0  2.1675    1  273.0   \n",
      "504  0.10959   0.0  11.93     0  0.573  6.794  89.3  2.3889    1  273.0   \n",
      "505  0.04741   0.0  11.93     0  0.573  6.030  80.8  2.5050    1  273.0   \n",
      "\n",
      "     PTRATIO       B  LSTAT  MEDV  anomaly  \n",
      "0       15.3  396.90   4.98  24.0        1  \n",
      "1       17.8  396.90   9.14  21.6        1  \n",
      "2       17.8  392.83   4.03  34.7        1  \n",
      "3       18.7  394.63   2.94  33.4        1  \n",
      "4       18.7  396.90   5.33  36.2        1  \n",
      "..       ...     ...    ...   ...      ...  \n",
      "501     21.0  391.99   9.67  22.4        1  \n",
      "502     21.0  396.90   9.08  20.6        1  \n",
      "503     21.0  396.90   5.64  23.9        1  \n",
      "504     21.0  393.45   6.48  22.0        1  \n",
      "505     21.0  396.90   7.88  11.9        1  \n",
      "\n",
      "[506 rows x 15 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "clf = IsolationForest(contamination=0.1)\n",
    "df_numeric = df.select_dtypes(include=['float64', 'int'])\n",
    "df['anomaly'] = clf.fit_predict(df_numeric)\n",
    "\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7c55b4f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         CRIM    ZN  INDUS  CHAS     NOX     RM    AGE      DIS  RAD    TAX  \\\n",
      "54    0.01360  75.0   4.00     0  0.4100  5.888   47.6   7.3197    3  469.0   \n",
      "55    0.01311  90.0   1.22     0  0.4030  7.249   21.9   8.6966    5  226.0   \n",
      "142   3.32105   0.0  19.58     1  0.8710  5.403  100.0   1.3216    5  403.0   \n",
      "144   2.77974   0.0  19.58     0  0.8710  4.903   97.8   1.3459    5  403.0   \n",
      "145   2.37934   0.0  19.58     0  0.8710  6.130  100.0   1.4191    5  403.0   \n",
      "152   1.12658   0.0  19.58     1  0.8710  5.012   88.0   1.6102    5  403.0   \n",
      "154   1.41385   0.0  19.58     1  0.8710  6.129   96.0   1.7494    5  403.0   \n",
      "155   3.53501   0.0  19.58     1  0.8710  6.152   82.6   1.7455    5  403.0   \n",
      "156   2.44668   0.0  19.58     0  0.8710  5.272   94.0   1.7364    5  403.0   \n",
      "162   1.83377   0.0  19.58     1  0.6050  7.802   98.2   2.0407    5  403.0   \n",
      "163   1.51902   0.0  19.58     1  0.6050  8.375   93.9   2.1620    5  403.0   \n",
      "195   0.01381  80.0   0.46     0  0.4220  7.875   32.0   5.6484    4  255.0   \n",
      "197   0.04666  80.0   1.52     0  0.4040  7.107   36.6   7.3090    2  329.0   \n",
      "200   0.01778  95.0   1.47     0  0.4030  7.135   13.9   7.6534    3  402.0   \n",
      "202   0.02177  82.5   2.03     0  0.4150  7.610   15.7   6.2700    2  348.0   \n",
      "203   0.03510  95.0   2.68     0  0.4161  7.853   33.2   5.1180    4  224.0   \n",
      "204   0.02009  95.0   2.68     0  0.4161  8.034   31.9   5.1180    4  224.0   \n",
      "253   0.36894  22.0   5.86     0  0.4310  8.259    8.4   8.9067    7  330.0   \n",
      "256   0.01538  90.0   3.75     0  0.3940  7.454   34.2   6.3361    3  244.0   \n",
      "257   0.61154  20.0   3.97     0  0.6470  8.704   86.9   1.8010    5  264.0   \n",
      "262   0.52014  20.0   3.97     0  0.6470  8.398   91.5   2.2885    5  264.0   \n",
      "267   0.57834  20.0   3.97     0  0.5750  8.297   67.0   2.4216    5  264.0   \n",
      "282   0.06129  20.0   3.33     1  0.4429  7.645   49.7   5.2119    5  216.0   \n",
      "283   0.01501  90.0   1.21     1  0.4010  7.923   24.8   5.8850    1  198.0   \n",
      "286   0.01965  80.0   1.76     0  0.3850  6.230   31.5   9.0892    1  241.0   \n",
      "351   0.07950  60.0   1.69     0  0.4110  6.579   35.9  10.7103    4  411.0   \n",
      "352   0.07244  60.0   1.69     0  0.4110  5.884   18.5  10.7103    4  411.0   \n",
      "353   0.01709  90.0   2.02     0  0.4100  6.728   36.1  12.1265    5  187.0   \n",
      "354   0.04301  80.0   1.91     0  0.4130  5.663   21.9  10.5857    4  334.0   \n",
      "355   0.10659  80.0   1.91     0  0.4130  5.936   19.5  10.5857    4  334.0   \n",
      "356   8.98296   0.0  18.10     1  0.7700  6.212   97.4   2.1222   24  666.0   \n",
      "357   3.84970   0.0  18.10     1  0.7700  6.395   91.0   2.5052   24  666.0   \n",
      "358   5.20177   0.0  18.10     1  0.7700  6.127   83.4   2.7227   24  666.0   \n",
      "363   4.22239   0.0  18.10     1  0.7700  5.803   89.0   1.9047   24  666.0   \n",
      "364   3.47428   0.0  18.10     1  0.7180  8.780   82.9   1.9047   24  666.0   \n",
      "368   4.89822   0.0  18.10     0  0.6310  4.970  100.0   1.3325   24  666.0   \n",
      "369   5.66998   0.0  18.10     1  0.6310  6.683   96.8   1.3567   24  666.0   \n",
      "370   6.53876   0.0  18.10     1  0.6310  7.016   97.5   1.2024   24  666.0   \n",
      "372   8.26725   0.0  18.10     1  0.6680  5.875   89.6   1.1296   24  666.0   \n",
      "374  18.49820   0.0  18.10     0  0.6680  4.138  100.0   1.1370   24  666.0   \n",
      "380  88.97620   0.0  18.10     0  0.6710  6.968   91.9   1.4165   24  666.0   \n",
      "404  41.52920   0.0  18.10     0  0.6930  5.531   85.4   1.6074   24  666.0   \n",
      "405  67.92080   0.0  18.10     0  0.6930  5.683  100.0   1.4254   24  666.0   \n",
      "410  51.13580   0.0  18.10     0  0.5970  5.757  100.0   1.4130   24  666.0   \n",
      "412  18.81100   0.0  18.10     0  0.5970  4.628  100.0   1.5539   24  666.0   \n",
      "414  45.74610   0.0  18.10     0  0.6930  4.519  100.0   1.6582   24  666.0   \n",
      "418  73.53410   0.0  18.10     0  0.6790  5.957  100.0   1.8026   24  666.0   \n",
      "427  37.66190   0.0  18.10     0  0.6790  6.202   78.7   1.8629   24  666.0   \n",
      "438  13.67810   0.0  18.10     0  0.7400  5.935   87.9   1.8206   24  666.0   \n",
      "489   0.18337   0.0  27.74     0  0.6090  5.414   98.3   1.7554    4  711.0   \n",
      "490   0.20746   0.0  27.74     0  0.6090  5.093   98.0   1.8226    4  711.0   \n",
      "\n",
      "     PTRATIO       B  LSTAT  MEDV  anomaly  \n",
      "54      21.1  396.90  14.80  18.9       -1  \n",
      "55      17.9  395.93   4.81  35.4       -1  \n",
      "142     14.7  396.90  26.82  13.4       -1  \n",
      "144     14.7  396.90  29.29  11.8       -1  \n",
      "145     14.7  172.91  27.80  13.8       -1  \n",
      "152     14.7  343.28  12.12  15.3       -1  \n",
      "154     14.7  321.02  15.12  17.0       -1  \n",
      "155     14.7   88.01  15.02  15.6       -1  \n",
      "156     14.7   88.63  16.14  13.1       -1  \n",
      "162     14.7  389.61   1.92  50.0       -1  \n",
      "163     14.7  388.45   3.32  50.0       -1  \n",
      "195     14.4  394.23   2.97  50.0       -1  \n",
      "197     12.6  354.31   8.61  30.3       -1  \n",
      "200     17.0  384.30   4.45  32.9       -1  \n",
      "202     14.7  395.38   3.11  42.3       -1  \n",
      "203     14.7  392.78   3.81  48.5       -1  \n",
      "204     14.7  390.55   2.88  50.0       -1  \n",
      "253     19.1  396.90   3.54  42.8       -1  \n",
      "256     15.9  386.34   3.11  44.0       -1  \n",
      "257     13.0  389.70   5.12  50.0       -1  \n",
      "262     13.0  386.86   5.91  48.8       -1  \n",
      "267     13.0  384.54   7.44  50.0       -1  \n",
      "282     14.9  377.07   3.01  46.0       -1  \n",
      "283     13.6  395.52   3.16  50.0       -1  \n",
      "286     18.2  341.60  12.93  20.1       -1  \n",
      "351     18.3  370.78   5.49  24.1       -1  \n",
      "352     18.3  392.33   7.79  18.6       -1  \n",
      "353     17.0  384.46   4.50  30.1       -1  \n",
      "354     22.0  382.80   8.05  18.2       -1  \n",
      "355     22.0  376.04   5.57  20.6       -1  \n",
      "356     20.2  377.73  17.60  17.8       -1  \n",
      "357     20.2  391.34  13.27  21.7       -1  \n",
      "358     20.2  395.43  11.48  22.7       -1  \n",
      "363     20.2  353.04  14.64  16.8       -1  \n",
      "364     20.2  354.55   5.29  21.9       -1  \n",
      "368     20.2  375.52   3.26  50.0       -1  \n",
      "369     20.2  375.33   3.73  50.0       -1  \n",
      "370     20.2  392.05   2.96  50.0       -1  \n",
      "372     20.2  347.88   8.88  50.0       -1  \n",
      "374     20.2  396.90  37.97  13.8       -1  \n",
      "380     20.2  396.90  17.21  10.4       -1  \n",
      "404     20.2  329.46  27.38   8.5       -1  \n",
      "405     20.2  384.97  22.98   5.0       -1  \n",
      "410     20.2    2.60  10.11  15.0       -1  \n",
      "412     20.2   28.79  34.37  17.9       -1  \n",
      "414     20.2   88.27  36.98   7.0       -1  \n",
      "418     20.2   16.45  20.62   8.8       -1  \n",
      "427     20.2   18.82  14.52  10.9       -1  \n",
      "438     20.2   68.95  34.02   8.4       -1  \n",
      "489     20.1  344.05  23.97   7.0       -1  \n",
      "490     20.1  318.43  29.68   8.1       -1  \n"
     ]
    }
   ],
   "source": [
    "print(df[df['anomaly'] == -1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a8ab2805",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Load JSONL as Hugging Face Dataset\n",
    "dataset = load_dataset(\"json\", data_files=\"llm_data_quality_training_set.jsonl\", split=\"train\")\n",
    "\n",
    "# Optional: Split into train and test\n",
    "dataset = dataset.train_test_split(test_size=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ec7e7801",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 94/94 [00:00<00:00, 7252.84 examples/s]\n",
      "Map: 100%|██████████| 11/11 [00:00<00:00, 1131.98 examples/s]\n"
     ]
    }
   ],
   "source": [
    "def format_zephyr(example):\n",
    "    return {\n",
    "        \"text\": f\"<|system|>\\nYou are a helpful data quality assistant.\\n<|user|>\\n{example['prompt']}<|assistant|>\\n{example['response']}\"\n",
    "    }\n",
    "\n",
    "dataset = dataset.map(format_zephyr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3025b85f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 94/94 [00:00<00:00, 2456.65 examples/s]\n",
      "Map: 100%|██████████| 11/11 [00:00<00:00, 3527.32 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_id = \"HuggingFaceH4/zephyr-7b-beta\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "\n",
    "def tokenize(example):\n",
    "    return tokenizer(\n",
    "        example[\"text\"],\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=512\n",
    "    )\n",
    "\n",
    "tokenized = dataset.map(tokenize, batched=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "01971f5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 8/8 [00:06<00:00,  1.15it/s]\n",
      "Some parameters are on the meta device because they were offloaded to the disk and cpu.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    device_map=\"auto\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2fa82d4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.51.0\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "print(transformers.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0c037aa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transformers.training_args\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments\n",
    "print(TrainingArguments.__module__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "035fd015",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./zephyr-quality-checker\",\n",
    "    per_device_train_batch_size=2,\n",
    "    per_device_eval_batch_size=2,\n",
    "    num_train_epochs=3,\n",
    "    learning_rate=2e-5,\n",
    "    fp16=True,\n",
    "    eval_strategy=\"epoch\",   # ✅ spelling must be exact\n",
    "    save_strategy=\"epoch\",         # ✅ this too\n",
    "    logging_steps=10,\n",
    "    save_total_limit=2\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3a1284dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Roshan\\AppData\\Local\\Temp\\ipykernel_19076\\2239021662.py:3: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "You shouldn't move a model that is dispatched using accelerate hooks.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "You can't move a model that has some modules offloaded to cpu or disk.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Trainer, DataCollatorForLanguageModeling\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m trainer = \u001b[43mTrainer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtraining_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtokenized\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtrain\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43meval_dataset\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtokenized\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtest\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata_collator\u001b[49m\u001b[43m=\u001b[49m\u001b[43mDataCollatorForLanguageModeling\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmlm\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Roshan\\Desktop\\CS 541\\llm-data-quality\\Lib\\site-packages\\transformers\\utils\\deprecation.py:172\u001b[39m, in \u001b[36mdeprecate_kwarg.<locals>.wrapper.<locals>.wrapped_func\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    168\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m minimum_action \u001b[38;5;129;01min\u001b[39;00m (Action.NOTIFY, Action.NOTIFY_ALWAYS) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torchdynamo_compiling():\n\u001b[32m    169\u001b[39m     \u001b[38;5;66;03m# DeprecationWarning is ignored by default, so we use FutureWarning instead\u001b[39;00m\n\u001b[32m    170\u001b[39m     warnings.warn(message, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel=\u001b[32m2\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m172\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Roshan\\Desktop\\CS 541\\llm-data-quality\\Lib\\site-packages\\transformers\\trainer.py:614\u001b[39m, in \u001b[36mTrainer.__init__\u001b[39m\u001b[34m(self, model, args, data_collator, train_dataset, eval_dataset, processing_class, model_init, compute_loss_func, compute_metrics, callbacks, optimizers, optimizer_cls_and_kwargs, preprocess_logits_for_metrics)\u001b[39m\n\u001b[32m    609\u001b[39m \u001b[38;5;66;03m# Bnb Quantized models doesn't support `.to` operation.\u001b[39;00m\n\u001b[32m    610\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    611\u001b[39m     \u001b[38;5;28mself\u001b[39m.place_model_on_device\n\u001b[32m    612\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(model, \u001b[33m\"\u001b[39m\u001b[33mquantization_method\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) == QuantizationMethod.BITS_AND_BYTES\n\u001b[32m    613\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m614\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_move_model_to_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    616\u001b[39m \u001b[38;5;66;03m# Force n_gpu to 1 to avoid DataParallel as MP will manage the GPUs\u001b[39;00m\n\u001b[32m    617\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.is_model_parallel:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Roshan\\Desktop\\CS 541\\llm-data-quality\\Lib\\site-packages\\transformers\\trainer.py:901\u001b[39m, in \u001b[36mTrainer._move_model_to_device\u001b[39m\u001b[34m(self, model, device)\u001b[39m\n\u001b[32m    900\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_move_model_to_device\u001b[39m(\u001b[38;5;28mself\u001b[39m, model, device):\n\u001b[32m--> \u001b[39m\u001b[32m901\u001b[39m     model = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    902\u001b[39m     \u001b[38;5;66;03m# Moving a model to an XLA device disconnects the tied weights, so we have to retie them.\u001b[39;00m\n\u001b[32m    903\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.args.parallel_mode == ParallelMode.TPU \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(model, \u001b[33m\"\u001b[39m\u001b[33mtie_weights\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Roshan\\Desktop\\CS 541\\llm-data-quality\\Lib\\site-packages\\accelerate\\big_modeling.py:459\u001b[39m, in \u001b[36mdispatch_model.<locals>.add_warning.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    457\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m param \u001b[38;5;129;01min\u001b[39;00m model.parameters():\n\u001b[32m    458\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m param.device == torch.device(\u001b[33m\"\u001b[39m\u001b[33mmeta\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m459\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mYou can\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt move a model that has some modules offloaded to cpu or disk.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    460\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m fn(*args, **kwargs)\n",
      "\u001b[31mRuntimeError\u001b[39m: You can't move a model that has some modules offloaded to cpu or disk."
     ]
    }
   ],
   "source": [
    "from transformers import Trainer, DataCollatorForLanguageModeling\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized[\"train\"],\n",
    "    eval_dataset=tokenized[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=DataCollatorForLanguageModeling(tokenizer, mlm=False)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0160757a",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a99a96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = \"<|system|>\\nYou are a helpful data quality assistant.\\n<|user|>\\nAnalyze the following row: {'RM': None, 'TAX': 300, 'RAD': 24}<|assistant|>\\n\"\n",
    "inputs = tokenizer(input_text, return_tensors=\"pt\").to(model.device)\n",
    "outputs = model.generate(**inputs, max_new_tokens=100)\n",
    "print(tokenizer.decode(outputs[0], skip_special_tokens=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2dd222",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(\"fine-tuned-zephyr\")\n",
    "tokenizer.save_pretrained(\"fine-tuned-zephyr\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-data-quality",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
